{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime as dt, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "seed = 42  # choose any seed you prefer\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters and Lstm hyperparameters\n",
    "window_size = 100 # lstm input size\n",
    "\n",
    "input_window_size = 100\n",
    "\n",
    "target_window_size = 10 # lstm output size\n",
    "\n",
    "hidden_size = 1000\n",
    "\n",
    "num_layers = 4\n",
    "\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, item, timespan, start_date_str, end_date_str):\n",
    "        self.directory = f'C:/Github/DL-FinalProject/csvfiles/{item}'\n",
    "        self.item = item\n",
    "        self.timespan = timespan\n",
    "        start_date = dt.strptime(start_date_str, '%Y-%m-%d').date()\n",
    "        end_date = dt.strptime(end_date_str, '%Y-%m-%d').date()\n",
    "        self.dates = [single_date.strftime(\"%Y-%m-%d\") for single_date in self.daterange(start_date, end_date)]\n",
    "        self.columns = [1, 4]  # Selecting open and close prices\n",
    "        self.filenames = self.get_filenames()\n",
    "\n",
    "    def daterange(self, start_date, end_date):\n",
    "        for n in range(int((end_date - start_date).days) + 1):\n",
    "            yield start_date + timedelta(n)\n",
    "\n",
    "    def get_filenames(self):\n",
    "        filenames = []\n",
    "        for date in self.dates:\n",
    "            filename = f\"{self.directory}/{self.item}-{self.timespan}-{date}.csv\"\n",
    "            if os.path.exists(filename):\n",
    "                filenames.append(filename)\n",
    "        return filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        df = pd.read_csv(filename, usecols=self.columns, header=None)\n",
    "        tensor = torch.tensor(df.values, dtype=torch.float)  # Return open and close prices\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def sliding_window_percentage(batch):\n",
    "    windows_percentage = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - input_window_size - target_window_size + 1):  # Create windows of size window_size\n",
    "            window = tensor[i:i+input_window_size+target_window_size]\n",
    "            pct_change = ((window[:, 1] - window[:, 0]) * 100 / window[:, 0])\n",
    "            windows_percentage.append(pct_change)\n",
    "    output_percentage = torch.stack(windows_percentage)\n",
    "\n",
    "    return output_percentage\n",
    "\n",
    "def sliding_window_binary(batch):\n",
    "    windows_binary = []\n",
    "    for tensor in batch:\n",
    "        for i in range(tensor.shape[0] - input_window_size - target_window_size+ 1):  # Create windows of size window_size\n",
    "            window = tensor[i:i+input_window_size+target_window_size]\n",
    "            binary_change = (window[:, 1] > window[:, 0]).float()  # Calculate the binary change\n",
    "            windows_binary.append(binary_change)\n",
    "    output_binary = torch.stack(windows_binary)\n",
    "\n",
    "    return output_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PriceDataset('BTCUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "test_dataset = PriceDataset('ETHUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "\n",
    "\n",
    "percentage_train_loader = DataLoader(train_dataset, batch_size=1, collate_fn=sliding_window_percentage, shuffle=False, drop_last=True)\n",
    "percentage_test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=sliding_window_percentage, shuffle=False, drop_last=True)\n",
    "\n",
    "binary_train_loader = DataLoader(train_dataset, batch_size=1, collate_fn=sliding_window_binary, shuffle=False, drop_last=True)\n",
    "binary_test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=sliding_window_binary, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in training DataLoader: 791\n",
      "Number of batches in testing DataLoader: 791\n"
     ]
    }
   ],
   "source": [
    "def count_batches(dataloader):\n",
    "    count = 0\n",
    "    for _ in dataloader:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "# Example usage\n",
    "train_batch_count = count_batches(percentage_train_loader)\n",
    "test_batch_count = count_batches(percentage_test_loader)\n",
    "\n",
    "print(f\"Number of batches in training DataLoader: {train_batch_count}\")\n",
    "print(f\"Number of batches in testing DataLoader: {test_batch_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows in train dataset: 1051827\n",
      "Total windows in test dataset: 1051827\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_total_windows(dataset, input_window_size, target_window_size):\n",
    "    total_windows = 0\n",
    "    for filename in dataset.filenames:\n",
    "        df = pd.read_csv(filename, usecols=dataset.columns, header=None)\n",
    "        # Calculate the number of windows in this file\n",
    "        num_rows = len(df)\n",
    "        if num_rows >= input_window_size + target_window_size:\n",
    "            windows_in_file = num_rows - input_window_size - target_window_size + 1\n",
    "            total_windows += windows_in_file\n",
    "    return total_windows\n",
    "\n",
    "# Example usage\n",
    "total_train_windows = count_total_windows(train_dataset, input_window_size, target_window_size)\n",
    "total_test_windows = count_total_windows(test_dataset, input_window_size, target_window_size)\n",
    "\n",
    "print(f\"Total windows in train dataset: {total_train_windows}\")\n",
    "print(f\"Total windows in test dataset: {total_test_windows}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
