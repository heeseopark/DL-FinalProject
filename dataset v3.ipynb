{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime as dt, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "seed = 42  # choose any seed you prefer\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters and Lstm hyperparameters\n",
    "window_size = 100 # lstm input size\n",
    "\n",
    "input_window_size = 100\n",
    "\n",
    "target_window_size = 10 # lstm output size\n",
    "\n",
    "hidden_size = 1000\n",
    "\n",
    "num_layers = 4\n",
    "\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input sequence: 100 <- 조절 가능하게 해야함. 그리고 input sequence는 가격 값을 input 받음\n",
    "\n",
    "output sequence: 10 <- 이것 또한 조절 가능하게 해야함. 그리고 output sequence는 상승/하락 binary를 받음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset v2는 전체 csv file을 합친 후에 dataloader에 전달하려고 한 것인데, 메모리 문제로 load하지 못하는 문제가 있었음.\n",
    "\n",
    "그래서 v3에서는 날짜마다 load 하되, 한 날의 마지막 부분에 data가 짤리는 경우에는 다음 날짜가 존재하는지 확인한 뒤에, 뒤의 data를 가져와서 dataloader에 보내는 것으로 결정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가격 자체가 중요한 것이 아니기 때문에 가격 변동값을 input으로 넣을 것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, item, timespan, start_date_str, end_date_str):\n",
    "        self.directory = f'C:/Github/DL-FinalProject/csvfiles/{item}'\n",
    "        self.item = item\n",
    "        self.timespan = timespan\n",
    "        start_date = dt.strptime(start_date_str, '%Y-%m-%d').date()\n",
    "        end_date = dt.strptime(end_date_str, '%Y-%m-%d').date()\n",
    "        self.dates = [single_date.strftime(\"%Y-%m-%d\") for single_date in self.daterange(start_date, end_date)]\n",
    "        self.columns = [1, 4]  # Selecting open and close prices\n",
    "        self.filenames = self.get_filenames()\n",
    "\n",
    "    def daterange(self, start_date, end_date):\n",
    "        for n in range(int((end_date - start_date).days) + 1):\n",
    "            yield start_date + timedelta(n)\n",
    "\n",
    "    def __len__(self):\n",
    "        total_length = 0\n",
    "        for filename in self.filenames:\n",
    "            df = pd.read_csv(filename, usecols=self.columns, header=None)\n",
    "            total_length += len(df)\n",
    "\n",
    "        # Adjust for the fact that the last few entries in the dataset may not form a complete window\n",
    "        return max(0, total_length - input_window_size - target_window_size + 1)\n",
    "    \n",
    "    def get_filenames(self):\n",
    "        filenames = []\n",
    "        for date in self.dates:\n",
    "            filename = f\"{self.directory}/{self.item}-{self.timespan}-{date}.csv\"\n",
    "            if os.path.exists(filename):\n",
    "                filenames.append(filename)\n",
    "        return filenames\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = max(0, idx - input_window_size - target_window_size + 1)\n",
    "        end_idx = min(idx + 1, len(self.filenames))\n",
    "\n",
    "        tensors = []\n",
    "        for file_idx in range(start_idx, end_idx):\n",
    "            filename = self.filenames[file_idx]\n",
    "            df = pd.read_csv(filename, usecols=self.columns, header=None)\n",
    "            tensor = torch.tensor(df.values, dtype=torch.float)\n",
    "            tensors.append(tensor)\n",
    "\n",
    "        combined_tensor = torch.cat(tensors, dim=0)\n",
    "        return combined_tensor\n",
    "\n",
    "\n",
    "def sliding_window_percentage(batch):\n",
    "    windows_percentage = []\n",
    "    for tensor in batch:\n",
    "        total_length = tensor.shape[0]\n",
    "        for i in range(total_length - input_window_size - target_window_size + 1):\n",
    "            window = tensor[i:i + input_window_size + target_window_size]\n",
    "            pct_change = ((window[-target_window_size:, 1] - window[:input_window_size, 0]) * 100 / window[:input_window_size, 0])\n",
    "            windows_percentage.append(pct_change)\n",
    "\n",
    "    output_percentage = torch.stack(windows_percentage)\n",
    "    return output_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PriceDataset('BTCUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dataset = PriceDataset('ETHUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows in train dataset: 1137937\n",
      "Total windows in test dataset: 1137937\n"
     ]
    }
   ],
   "source": [
    "def count_total_windows(dataset):\n",
    "    total_length = 0\n",
    "    for filename in dataset.filenames:\n",
    "        df = pd.read_csv(filename, usecols=dataset.columns, header=None)\n",
    "        total_length += len(df)\n",
    "\n",
    "    # Adjust for the fact that the last few entries in the dataset may not form a complete window\n",
    "    total_windows = max(0, total_length - input_window_size - target_window_size + 1)\n",
    "    return total_windows\n",
    "\n",
    "# Example usage\n",
    "total_train_windows = count_total_windows(train_dataset)\n",
    "total_test_windows = count_total_windows(test_dataset)\n",
    "\n",
    "print(f\"Total windows in train dataset: {total_train_windows}\")\n",
    "print(f\"Total windows in test dataset: {total_test_windows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data at index 0:\n",
      " tensor([[45134.1094, 45260.7383],\n",
      "        [45252.6719, 45356.0000],\n",
      "        [45356.0000, 45128.5703],\n",
      "        ...,\n",
      "        [49622.9414, 49590.7695],\n",
      "        [49590.7812, 49598.2891],\n",
      "        [49600.0000, 49587.0312]])\n",
      "Length of index 0:\n",
      " 1440\n",
      "Data at index 1:\n",
      " tensor([[45134.1094, 45260.7383],\n",
      "        [45252.6719, 45356.0000],\n",
      "        [45356.0000, 45128.5703],\n",
      "        ...,\n",
      "        [48271.4297, 48282.4688],\n",
      "        [48284.5703, 48305.5898],\n",
      "        [48305.5898, 48440.6484]])\n",
      "Length of index 1:\n",
      " 2880\n",
      "Data at index 2:\n",
      " tensor([[45134.1094, 45260.7383],\n",
      "        [45252.6719, 45356.0000],\n",
      "        [45356.0000, 45128.5703],\n",
      "        ...,\n",
      "        [50499.6914, 50484.4219],\n",
      "        [50484.4219, 50446.0117],\n",
      "        [50441.3789, 50349.3711]])\n",
      "Length of index 2:\n",
      " 4320\n",
      "Data at index 3:\n",
      " tensor([[45134.1094, 45260.7383],\n",
      "        [45252.6719, 45356.0000],\n",
      "        [45356.0000, 45128.5703],\n",
      "        ...,\n",
      "        [48536.7305, 48496.2617],\n",
      "        [48496.2500, 48466.9492],\n",
      "        [48466.9414, 48374.0898]])\n",
      "Length of index 3:\n",
      " 5760\n",
      "Data at index 4:\n",
      " tensor([[45134.1094, 45260.7383],\n",
      "        [45252.6719, 45356.0000],\n",
      "        [45356.0000, 45128.5703],\n",
      "        ...,\n",
      "        [48891.4219, 48874.7383],\n",
      "        [48877.0898, 48845.3516],\n",
      "        [48840.6094, 48751.7109]])\n",
      "Length of index 4:\n",
      " 7200\n",
      "Data at index 5:\n",
      " tensor([[45134.1094, 45260.7383],\n",
      "        [45252.6719, 45356.0000],\n",
      "        [45356.0000, 45128.5703],\n",
      "        ...,\n",
      "        [48883.9609, 48882.5117],\n",
      "        [48882.5195, 48832.5703],\n",
      "        [48832.2383, 48882.1992]])\n",
      "Length of index 5:\n",
      " 8550\n",
      "Data at index 6:\n",
      " tensor([[45134.1094, 45260.7383],\n",
      "        [45252.6719, 45356.0000],\n",
      "        [45356.0000, 45128.5703],\n",
      "        ...,\n",
      "        [51237.1719, 51145.1914],\n",
      "        [51149.9883, 51119.2891],\n",
      "        [51119.2695, 50971.7500]])\n",
      "Length of index 6:\n",
      " 9990\n",
      "Data at index 7:\n",
      " tensor([[45134.1094, 45260.7383],\n",
      "        [45252.6719, 45356.0000],\n",
      "        [45356.0000, 45128.5703],\n",
      "        ...,\n",
      "        [52267.4102, 52277.3984],\n",
      "        [52277.3984, 52274.1719],\n",
      "        [52271.5312, 52375.1719]])\n",
      "Length of index 7:\n",
      " 11430\n",
      "Data at index 8:\n",
      " tensor([[45134.1094, 45260.7383],\n",
      "        [45252.6719, 45356.0000],\n",
      "        [45356.0000, 45128.5703],\n",
      "        ...,\n",
      "        [54804.1914, 54821.7695],\n",
      "        [54821.7695, 54864.6914],\n",
      "        [54864.6797, 54884.5000]])\n",
      "Length of index 8:\n",
      " 12870\n",
      "Data at index 9:\n",
      " tensor([[45134.1094, 45260.7383],\n",
      "        [45252.6719, 45356.0000],\n",
      "        [45356.0000, 45128.5703],\n",
      "        ...,\n",
      "        [55938.4492, 55966.8594],\n",
      "        [55971.9102, 56015.1406],\n",
      "        [56011.8789, 55851.5898]])\n",
      "Length of index 9:\n",
      " 14310\n",
      "Data at index 10:\n",
      " tensor([[45134.1094, 45260.7383],\n",
      "        [45252.6719, 45356.0000],\n",
      "        [45356.0000, 45128.5703],\n",
      "        ...,\n",
      "        [57806.2305, 57792.8516],\n",
      "        [57787.9883, 57765.3086],\n",
      "        [57762.9492, 57773.1602]])\n",
      "Length of index 10:\n",
      " 15750\n"
     ]
    }
   ],
   "source": [
    "# Assuming PriceDataset is defined and instantiated\n",
    "# Example: price_dataset = PriceDataset('BTCUSDT', '1m', '2021-03-01', '2023-04-30')\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    data = train_dataset[i]\n",
    "    print(f\"Data at index {i}:\\n\", data)\n",
    "    print(f\"Length of index {i}:\\n\", len(data))\n",
    "\n",
    "    # Optional: Break the loop after a few iterations to avoid too much output\n",
    "    if i >= 10:  # for example, only print the first 10 entries\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Github\\DL-FinalProject\\dataset v3.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Assuming train_loader is a DataLoader object\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(batch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Exit after the first batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Github\\DL-FinalProject\\dataset v3.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X13sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(df\u001b[39m.\u001b[39mvalues, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X13sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     tensors\u001b[39m.\u001b[39mappend(tensor)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X13sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m combined_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(tensors, dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X13sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mreturn\u001b[39;00m combined_tensor\n",
      "\u001b[1;31mRuntimeError\u001b[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "# Assuming train_loader is a DataLoader object\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break  # Exit after the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Github\\DL-FinalProject\\dataset v3.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m  \u001b[39m# We only want the first batch, so break after fetching it\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Using the function on the train_loader\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m print_first_data_batch(train_loader)\n",
      "\u001b[1;32mc:\\Github\\DL-FinalProject\\dataset v3.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_first_data_batch\u001b[39m(data_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# Fetch the first batch of data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m data_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFirst batch of data:\u001b[39m\u001b[39m\"\u001b[39m, data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\heeseopark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Github\\DL-FinalProject\\dataset v3.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(df\u001b[39m.\u001b[39mvalues, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     tensors\u001b[39m.\u001b[39mappend(tensor)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m combined_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(tensors, dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Github/DL-FinalProject/dataset%20v3.ipynb#X11sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mreturn\u001b[39;00m combined_tensor\n",
      "\u001b[1;31mRuntimeError\u001b[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "# Creating a simple function to fetch and print the first batch of data from the DataLoader\n",
    "\n",
    "def print_first_data_batch(data_loader):\n",
    "    # Fetch the first batch of data\n",
    "    for data in data_loader:\n",
    "        print(\"First batch of data:\", data)\n",
    "        break  # We only want the first batch, so break after fetching it\n",
    "\n",
    "# Using the function on the train_loader\n",
    "print_first_data_batch(train_loader)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
